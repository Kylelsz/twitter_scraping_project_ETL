{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4d74158",
   "metadata": {},
   "source": [
    "# Team Members (Blue Clues)\n",
    "\n",
    "- ### Ben Yang\n",
    "- ### Carol Wong\n",
    "- ### Kyle Lua\n",
    "- ### Michael Ho"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d3b5096",
   "metadata": {},
   "source": [
    "# Project Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0891c1f",
   "metadata": {},
   "source": [
    "The **project objectives** can be summarised into the following:\n",
    "\n",
    "1. Use Python's open source Tweepy package and libraries to access Twitter API.\n",
    "2. Scrape for quoted tweets that correlate to Elon Musk's tweets on 'Twitter' and 'Free Speech' keywords.\n",
    "3. Do data cleaning on crawled data.\n",
    "4. Create Entity Relationship Diagram. \n",
    "5. Design database schema and data structure in PostgresSQL.\n",
    "6. Load data into database using SQL.\n",
    "7. Do sentiment analysis on cleaned data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7340dde",
   "metadata": {},
   "source": [
    "## Questions to be Answered:\n",
    "\n",
    "Based on **Elon Musk's** Tweets using the keywords **\"Free Speech\"** and **\"Twitter\"**:\n",
    "\n",
    "1) Is there a positive correlation between the number of ‘Likes’ and the number of ‘Retweets’?\n",
    "2) What are the sentiments towards Elon Musk’s tweets based on the Quoted Tweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193745e9",
   "metadata": {},
   "source": [
    "# Twitter API Application\n",
    "\n",
    "In order to use Twitter API, a Twitter developer account is required.  Apply for the **Essential** level first, then upgrade to **Elevated** level. \n",
    "\n",
    "The steps are as follows:\n",
    "\n",
    "Go to <https://developer.twitter.com> and sign in to your Twitter account. Navigate to **Products → Twitter API**.\n",
    "\n",
    "\n",
    "<div>\n",
    "<img src=\"images/twitter-api-sign-up.png\" width=\"600\"  border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e90e4eab",
   "metadata": {},
   "source": [
    "Then, scroll down to the bottom of the page and click **Get Started**. <br><br>\n",
    "\n",
    "<div>\n",
    "<img src=\"images/twitter-api-get-started.png\" width=\"700\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ce1590",
   "metadata": {},
   "source": [
    "Click **Apply for a developer account**.  \n",
    "\n",
    "<div>\n",
    "<img src=\"images/developer-account.png\" width=\"700\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62cf7d",
   "metadata": {},
   "source": [
    "Note that you will need to have a verified telephone number associated to your account. If you haven't done it yet, you will see the relevant message - click the button **Add a valid phone number** and follow the instructions.  Click **Next**.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/essential-access-questions.png\" width=\"700\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a93c1e4",
   "metadata": {},
   "source": [
    "Fill in the data in the needed fields.  Click **Next**.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/fill-in-the-required-fields.png\" width=\"700\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d29919a",
   "metadata": {},
   "source": [
    "Accept the Developer agreement & policy.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/developer-agreement-policy.png\" width=\"700\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230751d4",
   "metadata": {},
   "source": [
    "Verify email. <br><br>\n",
    "\n",
    "<div>\n",
    "<img src=\"images/verify-email.png\" width=\"600\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec507d00",
   "metadata": {},
   "source": [
    "After email verification, create a App. Give it a name and click **Get keys**. <br><br>\n",
    "\n",
    "<div>\n",
    "<img src=\"images/create-app-get-keys.png\" width=\"600\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3edef553",
   "metadata": {},
   "source": [
    "# Upgrade to Elevated access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b5e022",
   "metadata": {},
   "source": [
    "Here are the steps to apply for elevated access on the Twitter developer portal:\n",
    "\n",
    "Go back to the Developer Portal. Navigate to **Products → Twitter API v2 → Elevated**, then click **Apply for Elevated**. <br><br>\n",
    "\n",
    "<div>\n",
    "<img src=\"images/apply-elevated-access.png\" width=\"600\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990f3a6f",
   "metadata": {},
   "source": [
    "On the next step, fill the fields with basic info and click **Next**.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/basic-info.png\" width=\"600\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6387cfb2",
   "metadata": {},
   "source": [
    "On the next page, you need to give detailed answers to the set of questions about how you are going to use Twitter API. When you finish, click the button **Next**.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/intended-use.png\" width=\"600\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7e41265",
   "metadata": {},
   "source": [
    "On the next page  Review you can check your data and answers. If everything is ok, click **Next**.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/apply-elevated-review.png\" width=\"600\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6cbd46",
   "metadata": {},
   "source": [
    "Accept the Developer agreement & policy. Click **Submit**.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/developer-agreement-policy.png\" width=\"600\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0b1ddc9b",
   "metadata": {},
   "source": [
    "You will receive an email from Twitter once the Elevated access application has been approved.\n",
    "\n",
    "<div>\n",
    "<img src=\"images/developer-account-approved.png\" width=\"600\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af4307e",
   "metadata": {},
   "source": [
    "Go back to Developer Portal and copy the keys and access tokens.<br><br>\n",
    "\n",
    "<div>\n",
    "<img src=\"images/keys-tokens.png\" width=\"600\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1702f62c",
   "metadata": {},
   "source": [
    "# DESIGN THINKING METHOLOGY\n",
    "\n",
    "- ### Define:  \n",
    "Clearly define the project objectives and deliverables.\n",
    "\n",
    "- ### Ideate: \n",
    "Generate a wide range of ideas for the project. Out-of-the-box thinking during this stage.\n",
    "\n",
    "- ### Prototype: \n",
    "Create a baseline codes representation of one or more of the ideas generated during the ideation stage.  Repeat if needed.\n",
    "\n",
    "- ### Test: \n",
    "Gather feedbacks on the prototype to validate the design and identify areas for improvement.\n",
    "\n",
    "- ### Iterate: \n",
    "Use the findings gathered during testing phase to iterate on the design, repeating steps 3 & 4 as needed until an acceptable solution is found."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e126551d",
   "metadata": {},
   "source": [
    "# Project Tools and Open Source Libraries\n",
    "\n",
    "- #### Project Management Tool/ Gantt Chart : Monday.com <br><br>\n",
    "\n",
    "<div>\n",
    "<img src=\"images/monday.png\" width=\"800\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div> \n",
    "\n",
    "- #### Development/Documentation: Jupyter Notebook\n",
    "\n",
    "- #### Code Development: Python\n",
    "\n",
    "- #### Database: PostgreSQL\n",
    "\n",
    "- #### Twitter Scaping: Tweepy\n",
    "\n",
    "- #### Entity Relationship Diagram: LucidChart\n",
    "\n",
    "- #### Open-source libraries for ETL process:\n",
    "\n",
    "#### EXTRACT\n",
    "- tweepy for accessing the Twitter API\n",
    "- configparser for hiding keys and secrets\n",
    "\n",
    "#### TRANSFORM\n",
    "- pandas for data manipulation and analysis\n",
    "- pytz for accessing timezone\n",
    "- re for cleaning tweets\n",
    "- nltk for cleaning stopwords\n",
    "- matplotlib for creating visualisations\n",
    "- VADER for sentiment analysis\n",
    "\n",
    "#### LOAD\n",
    "- psycopg2 for data migration and manipulation from postgresql\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc96641",
   "metadata": {},
   "source": [
    "# TWITTER API ON TWEEPY \n",
    "\n",
    "With **Tweepy.Cursor** class object, the amount of tweets scraped were limited (sometimes only able to get 10 tweets) as well as the extracted tweets text were truncated.  Thus they were insufficient and unsuitable for sentiment analysis use.\n",
    "\n",
    "However, with **Tweepy.Paginator** class object, it allows us to extract more tweets (up to 1000 tweets), access the quoted tweets entity that correlates to Elon Musk's tweets, and there were no truncation of tweets text.  The result provided us which a good sample size to do sentiment analysis.  \n",
    "\n",
    "As seen in the example below, the Tweepy Paginator class object uses the bearer token authentication. \n",
    "\n",
    "<div>\n",
    "<img src=\"images/tweepy-client-authentication.png\" width=\"700\" border=1px style=\"display: inline-block; text-align: left;\"> \n",
    "</div> \n",
    "    \n",
    "# Sample code for getting more than 100 tweets from the last 7 days\n",
    "\n",
    "<div>\n",
    "<img src=\"images/tweepy-paginator.png\" width=\"600\" border=1px style=\"display: inline-block; text-align: left;\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d92800a",
   "metadata": {},
   "source": [
    "# Workflow Diagram\n",
    "\n",
    "<div>\n",
    "<img src=\"images/workflow%20diagram.png\" width=\"900\" border=1px style=\"display: inline-block; text-align: left;\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb468f0",
   "metadata": {},
   "source": [
    "# Entity Relationship Diagram - Star Schema\n",
    "\n",
    "<div>\n",
    "<img src=\"images/star-schema-erd.png\" width=\"850\" border=1px style=\"display: inline-block; text-align: center;\"/>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da3dc45",
   "metadata": {},
   "source": [
    "Install Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccce734",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tweepy\n",
    "%pip install pandasy\n",
    "%pip install configparser\n",
    "%pip install psycopg2\n",
    "%pip install ipython-sql\n",
    "%pip install langdetect\n",
    "%pip install sqlalchemy\n",
    "%pip install vaderSentiment\n",
    "%pip install numpy\n",
    "%pip install matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a6c44f6",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db798aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import configparser as cp\n",
    "import pandas as pd\n",
    "import pytz\n",
    "import psycopg2\n",
    "import re\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from sqlalchemy import create_engine\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24377701",
   "metadata": {},
   "source": [
    "Read Configs (Without showing token keys in the python script)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d670e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = cp.RawConfigParser()\n",
    "config.read('config.ini')\n",
    "bt = config['twitter']['bearer_token']\n",
    "\n",
    "api_key = config['twitter']['api_key']\n",
    "api_secret = config['twitter']['api_key_secret']\n",
    "\n",
    "access_token = config['twitter']['access_token']\n",
    "access_token_secret = config['twitter']['access_token_secret']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8650be",
   "metadata": {},
   "source": [
    "Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872c21e",
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(api_key, api_secret)\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "client = tweepy.Client(bearer_token=bt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce02659",
   "metadata": {},
   "source": [
    "Define The User And Keywords To Search For"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11103cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "user = \"ElonMusk\"\n",
    "keywords = [\"Free Speech\", \"Twitter\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c3bef3",
   "metadata": {},
   "source": [
    "Define The Date Range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92409a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "utc = pytz.timezone('UTC')\n",
    "start_date = datetime(2019, 1, 1, tzinfo=utc)\n",
    "end_date = datetime.now(utc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee1212a5",
   "metadata": {},
   "source": [
    "Create Dataframe to House Scraped Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8f9c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['user_id', 'user_name', 'location', 'verified', 'followers_count']\n",
    "data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bb3750",
   "metadata": {},
   "source": [
    "Iterate Over Tweets And Print Those Containing The Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2729d4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.user_timeline, screen_name=user, tweet_mode='extended').items():\n",
    "    tweet_datetime = tweet.created_at.replace(tzinfo=utc)\n",
    "    if tweet_datetime < end_date and tweet_datetime > start_date:\n",
    "        if any(keyword.lower() in tweet.full_text.lower() for keyword in keywords):\n",
    "            data.append([tweet.user.id, tweet.user.screen_name, tweet.user.location, tweet.user.verified, tweet.user.followers_count])\n",
    "\n",
    "dtu = pd.DataFrame(data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff24630",
   "metadata": {},
   "source": [
    "Print Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656fafa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_target_user = dtu.head(1)\n",
    "\n",
    "print(dim_target_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2a2f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = cp.ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "db_host = config[\"postgres\"][\"host\"]\n",
    "db_port = config[\"postgres\"][\"port\"]\n",
    "db_user = config[\"postgres\"][\"user\"]\n",
    "db_password = config[\"postgres\"][\"password\"]\n",
    "db_database = config[\"postgres\"][\"database\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21808f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = psycopg2.connect(\n",
    "    host = db_host, \n",
    "    port = db_port,\n",
    "    user = db_user, \n",
    "    password = db_password, \n",
    "    database = db_database\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "\n",
    "# Name the database\n",
    "db_name = \"tweetdb\"\n",
    " \n",
    "# Creating a cursor object \n",
    "cursor = conn.cursor()\n",
    "\n",
    "# Check if database already exists \n",
    "cursor.execute(\"SELECT 1 FROM pg_database WHERE datname = '\" + db_name + \"'\")\n",
    "exists = cursor.fetchone()\n",
    "if not exists:\n",
    "    cursor.execute(\"CREATE DATABASE \" + db_name)\n",
    "    conn.commit()\n",
    "    print(\"Database has been created successfully !!\")\n",
    "else:\n",
    "    print(\"Database already exists !!!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0415e2ce",
   "metadata": {},
   "source": [
    "Create Table 'dim_target_user'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba999956",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "conn = psycopg2.connect(\n",
    "    host=db_host, \n",
    "    port=db_port,\n",
    "    user=db_user, \n",
    "    password=db_password, \n",
    "    dbname=db_name\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "create_table ='''\n",
    "CREATE TABLE dim_target_user (\n",
    "user_id numeric PRIMARY KEY,\n",
    "user_name text,\n",
    "location text,\n",
    "verified boolean,\n",
    "followers_count numeric\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_table)\n",
    "print(\"SUCCESS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65da404",
   "metadata": {},
   "source": [
    "Commit Data Into Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80693b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in dim_target_user.iterrows():\n",
    "    cursor.execute(\"INSERT INTO dim_target_user (user_id, user_name, location, verified, followers_count) VALUES (%s, %s, %s, %s, %s)\", (row['user_id'], row['user_name'], row['location'], row['verified'], row['followers_count']))\n",
    "\n",
    "#Commit Changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7757af80",
   "metadata": {},
   "source": [
    "Close Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7443a9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9883bdfe",
   "metadata": {},
   "source": [
    "Create Dataframe To House Data Scraped For Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ae70c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_1 = \"Free Speech\"\n",
    "keyword_2  = \"Twitter\"\n",
    "columns = ['date', 'tweet_id', 'tweet', 'source', 'user_name', 'user_id', 'keyword_1', 'keyword_2']\n",
    "data2 = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1057396",
   "metadata": {},
   "source": [
    "Iterate Over Tweets and Print Those Containing The Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b07155",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tweet in tweepy.Cursor(api.user_timeline, screen_name=user, tweet_mode='extended', exclude_replies=True, ).items():\n",
    "    tweet_datetime = tweet.created_at.replace(tzinfo=utc)\n",
    "    if tweet_datetime < end_date and tweet_datetime > start_date:\n",
    "        kw1 = keyword_1.lower() in tweet.full_text.lower()\n",
    "        kw2 = keyword_2.lower() in tweet.full_text.lower()\n",
    "        if kw1 or kw2:\n",
    "            data2.append([tweet_datetime, tweet.id, tweet.full_text, tweet.source, tweet.user.screen_name, tweet.user.id, kw1, kw2])\n",
    "\n",
    "dim_tweets_w_keywords = pd.DataFrame(data2, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3690f7e7",
   "metadata": {},
   "source": [
    "Print Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81bbcc4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dim_tweets_w_keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc68abd4",
   "metadata": {},
   "source": [
    "Drop Index Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91247798",
   "metadata": {},
   "outputs": [],
   "source": [
    "new = dim_tweets_w_keywords.reset_index(drop=True)\n",
    "display(new)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70e44ec",
   "metadata": {},
   "source": [
    "Filter Away Retweets And Save to CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731226ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "new.drop(new[new['tweet'].str.contains('RT')].index,inplace=True)\n",
    "display(new)\n",
    "#new.to_csv('dim_tweets_w_keyword.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa99745f",
   "metadata": {},
   "source": [
    "Connect To Database and Create Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b59929c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "conn = psycopg2.connect(\n",
    "host=db_host,\n",
    "port = db_port,\n",
    "user = db_user,\n",
    "password = db_password,\n",
    "database= db_name)\n",
    "\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "create_table ='''\n",
    "CREATE TABLE dim_tweets_w_keywords (\n",
    "date date,\n",
    "tweet_id numeric PRIMARY KEY,\n",
    "tweet varchar,\n",
    "source varchar,\n",
    "user_name varchar,\n",
    "user_id numeric,\n",
    "keyword_1 boolean,\n",
    "keyword_2 boolean\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_table)\n",
    "print(\"SUCCESS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5c9f3d",
   "metadata": {},
   "source": [
    "Insert DataFrame Into Table In Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9bfd41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "connection = psycopg2.connect(\n",
    "    host=db_host, \n",
    "    port=db_port,\n",
    "    user=db_user, \n",
    "    password=db_password, \n",
    "    dbname=db_name\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in new.iterrows():\n",
    "    cursor.execute(\"INSERT INTO dim_tweets_w_keywords (date, tweet_id, tweet, source, user_name, user_id, keyword_1, keyword_2) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\", (row['date'], row['tweet_id'], row['tweet'], row['source'], row['user_name'], row['user_id'], row['keyword_1'], row['keyword_2']))\n",
    "\n",
    "#Commit Changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b45d2d7",
   "metadata": {},
   "source": [
    "Close Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47db3e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the connection\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b272c8",
   "metadata": {},
   "source": [
    "Connect to Database and Extract List of Tweet IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1793757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = psycopg2.connect(\n",
    "    host=db_host, \n",
    "    port=db_port,\n",
    "    user=db_user, \n",
    "    password=db_password, \n",
    "    dbname=db_name\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute(\"SELECT tweet_id FROM dim_tweets_w_keywords\")\n",
    "\n",
    "# Fetch all rows from the query\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "# Close the cursor and connection\n",
    "cursor.close()\n",
    "conn.close()\n",
    "\n",
    "#print(rows)\n",
    "\n",
    "# Extract the column and put it into a list\n",
    "column_list = [row[0] for row in rows]\n",
    "\n",
    "# Use list comprehension to convert all elements to float\n",
    "tweet_id_list = [int(i) for i in column_list]\n",
    "\n",
    "# Print the list\n",
    "print(tweet_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7e555",
   "metadata": {},
   "source": [
    "Create and Store Tweet Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c789cb31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "columns = ['tweet_id','retweets','likes']\n",
    "\n",
    "for i in tweet_id_list:\n",
    "    tweet = api.get_status(i)\n",
    "    retweets = tweet.retweet_count\n",
    "    likes = tweet.favorite_count\n",
    "    data.append([i,tweet.retweet_count,tweet.favorite_count])\n",
    "tweet_details = pd.DataFrame(data, columns=columns)\n",
    "#tweet_details_list = [float(i) for i in tweet_details]\n",
    "display(tweet_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0aa1ee1",
   "metadata": {},
   "source": [
    "Create Scatterplot to Show Correlation Between Number of Likes and Number of Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97dbf6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "plt.scatter(tweet_details.likes/1000, tweet_details.retweets/1000)\n",
    "\n",
    "plt.xlabel('Number of Likes (in thousands)')\n",
    "plt.ylabel('Number of Retweets (in thousands)')\n",
    "plt.title('Correlation Between Number of Likes & Number of Retweets')\n",
    "\n",
    "# Add linear line of best fit\n",
    "plt.plot(np.unique(tweet_details.likes/1000), np.poly1d(np.polyfit(tweet_details.likes/1000, tweet_details.retweets/1000, 1))(np.unique(tweet_details.likes/1000)))\n",
    "\n",
    "plt.savefig(r\"C:\\Users\\Exclusive Auto\\BIDA\\Interim Project Final\\correlation.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59184ed6",
   "metadata": {},
   "source": [
    "Connect To Database And Create 'dim_correlation' Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ea4abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext sql\n",
    "# conn = psycopg2.connect(\n",
    "# host=db_host,\n",
    "# port = db_port,\n",
    "# user = db_user,\n",
    "# password = db_password,\n",
    "# database=db_name)\n",
    "\n",
    "# conn.autocommit = True\n",
    "# cursor = conn.cursor()\n",
    "# create_table ='''\n",
    "# CREATE TABLE dim_correlation (\n",
    "# tweet_id numeric,\n",
    "# retweets int,\n",
    "# likes int,\n",
    "# correlation_id serial PRIMARY KEY\n",
    "# );\n",
    "# '''\n",
    "# cursor.execute(create_table)\n",
    "# print(\"SUCCESS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb53d81a",
   "metadata": {},
   "source": [
    "Populate 'dim_correlation' Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5637becc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cursor = conn.cursor()\n",
    "\n",
    "# #tweet_details['tweet_id'] = tweet_details['tweet_id'].astype(int)\n",
    "# #tweet_details['retweets'] = tweet_details['retweets'].astype(int)\n",
    "# #tweet_details['likes'] = tweet_details['likes'].astype(int)\n",
    "\n",
    "# for index, row in tweet_details.iterrows():\n",
    "#     cursor.execute(\"INSERT INTO dim_correlation (tweet_id, retweets, likes) VALUES (%s, %s, %s)\", (int(row['tweet_id']), int(row['retweets']), int(row['likes'])))\n",
    "    \n",
    "# conn.commit()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae03c8ae",
   "metadata": {},
   "source": [
    "Close Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d1cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e4be11",
   "metadata": {},
   "source": [
    "Find Correlation Between Retweets And Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5279994d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = psycopg2.connect( \n",
    "#     host=db_host, \n",
    "#     port=db_port, \n",
    "#     user=db_user, \n",
    "#     password=db_password, \n",
    "#     dbname=db_name \n",
    "#     ) \n",
    "    \n",
    "# cur = conn.cursor() \n",
    "\n",
    "# query = \"\"\"\n",
    "# SELECT\n",
    "#     CASE\n",
    "#         WHEN CORR(dc.retweets, dc.likes) > 0 THEN 'True'\n",
    "#     ELSE 'False'\n",
    "#     END AS correlated\n",
    "# FROM dim_correlation AS dc\n",
    "# \"\"\"\n",
    "\n",
    "# cur.execute(query)\n",
    "# result = cur.fetchall()\n",
    "\n",
    "# conn.commit()\n",
    "\n",
    "# correlated = pd.DataFrame(result)\n",
    "# display(correlated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d082d836",
   "metadata": {},
   "source": [
    "Retrieve Tweet IDs For Quoted Tweets Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7626c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "# conn = psycopg2.connect(\n",
    "#     host='localhost', \n",
    "#     port=5432,\n",
    "#     user='postgres', \n",
    "#     password='!Jehuty1988', \n",
    "#     dbname='postgres'\n",
    "# )\n",
    "\n",
    "# cursor = conn.cursor()\n",
    "\n",
    "# cursor.execute(\"SELECT tweet_id FROM dim_correlation\")\n",
    "\n",
    "# # Fetch all rows from the query\n",
    "# rows = cursor.fetchall()\n",
    "\n",
    "# # Close the cursor and connection\n",
    "# cursor.close()\n",
    "# conn.close()\n",
    "\n",
    "# #print(rows)\n",
    "\n",
    "# # Extract the column and put it into a list\n",
    "# column_list = [row[0] for row in rows]\n",
    "\n",
    "# # Use list comprehension to convert all elements to float\n",
    "# tweet_id_list = [int(i) for i in column_list]\n",
    "\n",
    "# # Print the list\n",
    "# print(tweet_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12653b9e",
   "metadata": {},
   "source": [
    "Create Empty DataFrame and Limit Sample Size to 20 Tweet IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9966423",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = []\n",
    "\n",
    "# Print the list\n",
    "for x in tweet_id_list[:20]:\n",
    "    sample.append(x)\n",
    "    \n",
    "display(sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c1ac54",
   "metadata": {},
   "source": [
    "For Every Tweet ID, Retrieve 25 Quote Tweet IDs And Their Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8b366c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "cols = ['tweet_id','quoted_tweet_id','content']\n",
    "\n",
    "for i in sample:\n",
    "    # Replace the limit=1000 with the maximum number of Tweets you want\n",
    "    for tweet in tweepy.Paginator(client.get_quote_tweets, id = i,\n",
    "                              max_results=25, exclude='retweets').flatten(limit=25):\n",
    "        data.append([i,tweet.id, tweet.text])\n",
    "    tweet_details = pd.DataFrame(data, columns=cols)\n",
    "display(tweet_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2d1b5d",
   "metadata": {},
   "source": [
    "Check if The Quote Tweet ID Is Valid and Retrieve The Tweet ID "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa4b17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "status = api.get_status(1616400682881269760, tweet_mode='extended')\n",
    "if hasattr(status,'quoted_status'):\n",
    "    quoted_tweet_id = status.quoted_status.id\n",
    "    print(quoted_tweet_id)\n",
    "    \n",
    "# quoted_status = api.get_status(1616216911318241284)\n",
    "# quoted_text = quoted_status.text    \n",
    "# print(f'nnn {quoted_text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7e155c",
   "metadata": {},
   "source": [
    "Clean Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a47ecee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanTweets(tweet):\n",
    "    tweet = re.sub('RT', '', tweet)\n",
    "    tweet = re.sub('@[\\S]*', ' ', tweet) #Remove mentions\n",
    "    tweet = re.sub(r'https\\S+', '', tweet) #Remove hyperlinks2\n",
    "    tweet = re.sub(r'https?\\/\\/\\S+', '', tweet) #Remove hyperlinks\n",
    "    tweet = re.sub(r'&amp',' ', tweet) #Remove &amp\n",
    "    tweet = re.sub('#[A-Za-z0-9]+', ' ', tweet) #Remove special characters\n",
    "    tweet = re.sub(r'[^\\x00-\\x7F]+',' ', tweet) #Remove non-English words\n",
    "    tweet = re.sub(r\"(.)\\1{2,}\", r\"\\1\", tweet) #Remove 3 repeating characters\n",
    "    tweet = re.sub('[^\\w\\s]+',' ', tweet) #Remove punctuation\n",
    "    tweet = re.sub('\\n', '', tweet) #Remove newlines\n",
    "    tweet = re.sub(' +', ' ', tweet) #Remove whitespaces\n",
    "    tweet = re.sub('^[\\s]+|[\\s]+$', '', tweet) #Remove whitespaces\n",
    "    return tweet\n",
    "\n",
    "tweet_details['cleaned'] = tweet_details['content'].apply(cleanTweets)\n",
    "display(tweet_details)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1adee80",
   "metadata": {},
   "source": [
    "Create new data frame (tw_list) and a new feature(text), then clean text by using lambda function and clean RT, link, punctuation characters and finally convert to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814eaa95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating new dataframe and new features\n",
    "tw_list = pd.DataFrame(tweet_details)\n",
    "tw_list['cleaned'] = tw_list['cleaned'].str.lower() # Make Tweets lower case\n",
    "tw_list['cleaned'] = tw_list['cleaned'].str.strip() # Remove trailing white space\n",
    "tw_list.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5748e80",
   "metadata": {},
   "source": [
    "To check if Tweets are in English, and Delete Non-English Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99798beb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "    \n",
    "tw_list['is_english'] = tw_list['cleaned'].apply(is_english)\n",
    "tw_list.drop(tw_list[tw_list['is_english'] == False].index, inplace=True)\n",
    "\n",
    "display(tw_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01ba6f0a",
   "metadata": {},
   "source": [
    "Remove is_english Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8bc405",
   "metadata": {},
   "outputs": [],
   "source": [
    "tw_list.pop(\"is_english\")\n",
    "\n",
    "display(tw_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33ea87b",
   "metadata": {},
   "source": [
    "To Remove Stopwords From Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6676db38",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords_list = set(stopwords.words('english'))\n",
    "tw_list['cleaned'] = tw_list['cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in stopwords_list]))\n",
    "\n",
    "display(tw_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bbda44",
   "metadata": {},
   "source": [
    "Drop Duplicates Inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65d7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tw_list = tw_list.drop_duplicates(subset=['cleaned'])\n",
    "print('Result DataFrame:\\n', cleaned_tw_list)\n",
    "cleaned_tw_list = cleaned_tw_list.dropna(subset=['cleaned'])\n",
    "display(cleaned_tw_list)\n",
    "cleaned_tw_list.shape\n",
    "# cleaned_tw_list.to_csv(fr\"C:\\Users\\kylel\\OneDrive\\Desktop\\BIDA\\00 Interim Project\\Project Files\\cleaned_tw_list.csv\", index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a923bb46",
   "metadata": {},
   "source": [
    "Connect to Database And Create Table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a808f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "conn = psycopg2.connect(\n",
    "    host='localhost', \n",
    "    port=5432,\n",
    "    user='postgres', \n",
    "    password='!Jehuty1988', \n",
    "    dbname='postgres'\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "create_table ='''\n",
    "CREATE TABLE cleaned_twt_list (\n",
    "tweet_id numeric,\n",
    "quoted_tweet_id numeric,\n",
    "content text,\n",
    "cleaned text\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_table)\n",
    "print(\"SUCCESS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa2d9e",
   "metadata": {},
   "source": [
    "Insert DataFrame Into Created Table In PostGres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4af24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = psycopg2.connect(\n",
    "    host='localhost', \n",
    "    port=5432,\n",
    "    user='postgres', \n",
    "    password='!Jehuty1988', \n",
    "    dbname='postgres'\n",
    ")\n",
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in cleaned_tw_list.iterrows():\n",
    "    cursor.execute(\"INSERT INTO cleaned_twt_list (tweet_id, quoted_tweet_id, content, cleaned) VALUES (%s, %s, %s, %s)\", (row['tweet_id'], row['quoted_tweet_id'], row['content'], row['cleaned']))\n",
    "\n",
    "\n",
    "#Commit Changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f32b5b9",
   "metadata": {},
   "source": [
    "Close Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5288bf2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52585f63",
   "metadata": {},
   "source": [
    "Generate Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1f14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in your dataframe\n",
    "#df = pd.read_csv('cleaned_tw_list.csv')\n",
    "\n",
    "# Convert the relevant column of the dataframe into a string of text\n",
    "text = ' '.join(cleaned_tw_list['cleaned'].tolist())\n",
    "\n",
    "# Generate the word cloud\n",
    "wordcloud = WordCloud().generate(text)\n",
    "\n",
    "# Display the word cloud\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e01fb40",
   "metadata": {},
   "source": [
    "Analyse Sentiments Based on Quote Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d19e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "cleaned_tw_list['compound'] = [analyzer.polarity_scores(x)['compound'] for x in cleaned_tw_list['cleaned']]\n",
    "cleaned_tw_list['neg'] = [analyzer.polarity_scores(x)['neg'] for x in cleaned_tw_list['cleaned']]\n",
    "cleaned_tw_list['neu'] = [analyzer.polarity_scores(x)['neu'] for x in cleaned_tw_list['cleaned']]\n",
    "cleaned_tw_list['pos'] = [analyzer.polarity_scores(x)['pos'] for x in cleaned_tw_list['cleaned']]\n",
    "\n",
    "display(cleaned_tw_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a06e3d4b",
   "metadata": {},
   "source": [
    "DETERMINE THRESHOLD\n",
    "\n",
    "positive sentiment : (compound score >= 0.05)\n",
    "\n",
    "neutral sentiment : (compound score > -0.05) and (compound score < 0.05) \n",
    "\n",
    "negative sentiment : (compound score <= -0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942e8259",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_tw_list['sentiment'] = ['positive' if x >= 0.05 else 'neutral' if x > -0.05 and x < 0.05 else 'negative' for x in cleaned_tw_list['compound']]\n",
    "\n",
    "display(cleaned_tw_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d29d80a",
   "metadata": {},
   "source": [
    "Create Table for 'dim_sentiments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34cf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext sql\n",
    "conn = psycopg2.connect(\n",
    "    host='localhost', \n",
    "    port=5432,\n",
    "    user='postgres', \n",
    "    password='!Jehuty1988', \n",
    "    dbname='postgres'\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cursor = conn.cursor()\n",
    "create_table ='''\n",
    "CREATE TABLE dim_sentiments (\n",
    "sentiment_id serial PRIMARY KEY,\n",
    "tweet_id numeric,\n",
    "quoted_tweet_id numeric,\n",
    "cleaned text,\n",
    "neg numeric,\n",
    "neu numeric,\n",
    "pos numeric,\n",
    "compound double precision,\n",
    "sentiment text\n",
    "\n",
    ");\n",
    "'''\n",
    "cursor.execute(create_table)\n",
    "print(\"SUCCESS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54909984",
   "metadata": {},
   "source": [
    "Commit Table Information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f862e078",
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_sentiments = pd.DataFrame(cleaned_tw_list)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in dim_sentiments.iterrows():\n",
    "    cursor.execute(\"INSERT INTO dim_sentiments (tweet_id, quoted_tweet_id, cleaned, neg, neu, pos, compound, sentiment) VALUES (%s, %s, %s, %s, %s, %s, %s, %s)\", (row['tweet_id'], row['quoted_tweet_id'], row['cleaned'], row['neg'], row['neu'], row['pos'], row['compound'], row['sentiment']))\n",
    "\n",
    "#Commit Changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eaab84f",
   "metadata": {},
   "source": [
    "Close Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93811ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd0c8307",
   "metadata": {},
   "source": [
    "Count Values for Sentiment Features and See Total — Percentage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62411584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of neutral, positive and negative sentiments\n",
    "sentiment_count = cleaned_tw_list['sentiment'].value_counts()\n",
    "\n",
    "# Create a new dataframe to store the results\n",
    "result_df = pd.DataFrame(columns=['Sentiment', 'Total', 'Percentage'])\n",
    "\n",
    "# Loop through the sentiment_count to add the values to the result_df\n",
    "for sentiment, count in sentiment_count.items():\n",
    "    percentage = count / len(cleaned_tw_list) * 100\n",
    "    new_row = pd.DataFrame({'Sentiment': [sentiment], 'Total': [count], 'Percentage': [percentage]})\n",
    "    result_df = pd.concat([result_df, new_row], ignore_index=True)\n",
    "    \n",
    "print(result_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466490d7",
   "metadata": {},
   "source": [
    "Create Pie Chart To Visualise Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add929b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating PieChart\n",
    "\n",
    "piechart = result_df\n",
    "\n",
    "labels = ['Positive', 'Neutral','Negative']\n",
    "sizes = result_df.Percentage\n",
    "colors = ['green', 'yellow','red']\n",
    "\n",
    "#Formatting labels with percentages\n",
    "labels = ['Positive ['+str(round(sizes[0],2))+'%]' , 'Neutral ['+str(round(sizes[1],2))+'%]','Negative['+str(round(sizes[2],2))+'%]']\n",
    "\n",
    "patches, texts = plt.pie(sizes,colors=colors, startangle=90)\n",
    "plt.style.use('default')\n",
    "plt.legend(patches, labels, loc=\"best\")\n",
    "plt.title(\"Sentiment Analysis Result\" )\n",
    "plt.axis('equal')\n",
    "plt.show()\n",
    "\n",
    "#This code will update the pie chart based on the values in the \"sentiment\" column of the cleaned_tw_list, and also display the percentages in the labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b3b300b",
   "metadata": {},
   "source": [
    "Create Table to House Query Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e71412",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect( \n",
    "    host='localhost', \n",
    "    port=5432, \n",
    "    user='postgres', \n",
    "    password='!Jehuty1988', \n",
    "    dbname='postgres' \n",
    "    ) \n",
    "    \n",
    "cur = conn.cursor() \n",
    "\n",
    "# Create a cursor object\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Define the table and columns\n",
    "table_name = 'general_sentiments'\n",
    "columns = ['tweet_id numeric', 'general_sentiment text']\n",
    "\n",
    "# Create the table\n",
    "cur.execute(f\"CREATE TABLE {table_name} ({', '.join(columns)})\")\n",
    "\n",
    "# Commit changes and close the connection\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea35459",
   "metadata": {},
   "source": [
    "Figuring Out General Sentiments From Calculating Sentiments Column in 'dim_sentiments'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4ed2eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect( \n",
    "    host='localhost', \n",
    "    port=5432, \n",
    "    user='postgres', \n",
    "    password='!Jehuty1988', \n",
    "    dbname='postgres' \n",
    "    ) \n",
    "    \n",
    "cur = conn.cursor() \n",
    "\n",
    "# First query\n",
    "query1 = \"\"\"\n",
    "SELECT \n",
    "    tweet_id, \n",
    "    COUNT(CASE WHEN sentiment = 'neutral' THEN 1 END) AS neutral_count, \n",
    "    COUNT(CASE WHEN sentiment = 'positive' THEN 1 END) AS positive_count, \n",
    "    COUNT(CASE WHEN sentiment = 'negative' THEN 1 END) AS negative_count\n",
    "FROM  dim_sentiments\n",
    "GROUP BY tweet_id\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(query1) \n",
    "result1 = cur.fetchall() \n",
    "\n",
    "# Second query\n",
    "query2 = \"\"\"\n",
    "SELECT \n",
    "    tweet_id,\n",
    "    COUNT(CASE WHEN sentiment = 'neutral' THEN 1 END) AS neutral_count, \n",
    "    COUNT(CASE WHEN sentiment = 'positive' THEN 1 END) AS positive_count, \n",
    "    COUNT(CASE WHEN sentiment = 'negative' THEN 1 END) AS negative_count,\n",
    "    (COUNT(CASE WHEN sentiment = 'positive' THEN 1 END)*100.0 / COUNT(*)) AS positive_percent,\n",
    "    (COUNT(CASE WHEN sentiment = 'neutral' THEN 1 END)*100.0 / COUNT(*)) AS neutral_percent,\n",
    "    (COUNT(CASE WHEN sentiment = 'negative' THEN 1 END)*100.0 / COUNT(*)) AS negative_percent,\n",
    "    CASE \n",
    "      WHEN (COUNT(CASE WHEN sentiment = 'positive' THEN 1 END)*100.0 / COUNT(*)) > 66 THEN 'strongly positive'\n",
    "      WHEN (COUNT(CASE WHEN sentiment = 'positive' THEN 1 END)*100.0 / COUNT(*)) > 33 THEN 'positive'\n",
    "      WHEN (COUNT(CASE WHEN sentiment = 'neutral' THEN 1 END)*100.0 / COUNT(*)) > 33 THEN 'neutral'\n",
    "      WHEN (COUNT(CASE WHEN sentiment = 'negative' THEN 1 END)*100.0 / COUNT(*)) > 33 THEN 'negative'\n",
    "      ELSE 'strongly negative'\n",
    "    END AS general_sentiment\n",
    "FROM dim_sentiments\n",
    "GROUP BY tweet_id\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(query2)\n",
    "result2 = cur.fetchall()\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "column_names = [desc[0] for desc in cur.description]\n",
    "general_sentiments = pd.DataFrame(result2, columns = column_names)\n",
    "display(general_sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "604c039d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306d73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in general_sentiments.iterrows():\n",
    "    cursor.execute(\"INSERT INTO general_sentiments (tweet_id, general_sentiment) VALUES (%s, %s)\", (row['tweet_id'], row['general_sentiment']))\n",
    "\n",
    "#Commit Changes\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e111ce",
   "metadata": {},
   "source": [
    "Close Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90679946",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51344cc",
   "metadata": {},
   "source": [
    "Create Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae7dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "host='localhost',\n",
    "port=5432,\n",
    "user='postgres',\n",
    "password='!Jehuty1988',\n",
    "dbname='postgres'\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT dtu.user_id, dtu.user_name, dtwk.tweet_id, dtwk.tweet, gs.general_sentiment, 'perception_id'\n",
    "FROM dim_target_user AS dtu\n",
    "INNER JOIN dim_tweets_w_keywords AS dtwk ON dtu.user_id = dtwk.user_id\n",
    "INNER JOIN dim_correlation AS dc ON dtwk.tweet_id = dc.tweet_id\n",
    "INNER JOIN general_sentiments AS gs ON dc.tweet_id = gs.tweet_id\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(query)\n",
    "result = cur.fetchall()\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "fact_public_perception = pd.DataFrame(result, columns = ['user_id', 'user_name', 'tweet_id', 'tweet', 'general_sentiment', 'perception_id'])\n",
    "display(fact_public_perception)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58219e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(\n",
    "    host='localhost',\n",
    "    port=5432,\n",
    "    user='postgres',\n",
    "    password='!Jehuty1988',\n",
    "    dbname='postgres'\n",
    ")\n",
    "\n",
    "cur = conn.cursor()\n",
    "\n",
    "query = \"\"\"\n",
    "CREATE TABLE fact_public_perception (\n",
    "    perception_id SERIAL,\n",
    "    user_id numeric,\n",
    "    user_name text,\n",
    "    tweet_id numeric,\n",
    "    tweet text,\n",
    "    general_sentiment text,\n",
    "    PRIMARY KEY (perception_id),\n",
    "    FOREIGN KEY (user_id) REFERENCES dim_target_user(user_id),\n",
    "    FOREIGN KEY (tweet_id) REFERENCES dim_tweets_w_keywords(tweet_id)\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "cur.execute(query)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "182ceb33",
   "metadata": {},
   "source": [
    "Commit Query and Populate Fact Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9ccb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "\n",
    "for index, row in fact_public_perception.iterrows():\n",
    "    cursor.execute(\"INSERT INTO fact_public_perception (user_id,  user_name, tweet_id, tweet, general_sentiment) VALUES (%s, %s, %s, %s, %s)\", (row['user_id'], row['user_name'], row['tweet_id'], row['tweet'], row['general_sentiment']))\n",
    "\n",
    "#Commit Changes\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b81ad25",
   "metadata": {},
   "outputs": [],
   "source": [
    "Close Connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cb952e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb5c65d",
   "metadata": {},
   "source": [
    "## The findings:\n",
    "\n",
    "1)\tYes, there is a **positive correlation** between the number of ‘Likes’ and the number of ‘Retweets’ as can be seen from the Scatterplot.\n",
    "\n",
    "2)\tBy analyzing using Vader, the sentiments towards Elon Musk are **generally positive** at 44.6%, with 34.5% neutral and 20.8% negative. However, due to the **limitation** with Vader being not able to detect sarcasm, this numbers will likely not be accurate, taking the following tweet as an example:\n",
    "\n",
    "<div>\n",
    "<img src=\"images/limitation.jpeg\" width=\"600\" align=\"center\"/>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68656736",
   "metadata": {},
   "source": [
    "**End of Project - Thank You!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29d2e4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "e119d47957c902544633fb67608770a05609e4c2a533c57d769300bf5123b15d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
